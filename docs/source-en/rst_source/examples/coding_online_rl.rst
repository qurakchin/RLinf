Online Reinforcement Learning for Code Completion Agent
=======================================================

Online Reinforcement Learning for Code Completion Agent is an important application scenario in the RLinf framework.
Through integration with code editors like Continue, we can collect user preference feedback on code completions, enabling near real-time code generation and feedback learning to quickly improve code completion quality and align with user preferences.
This example demonstrates how to use the RLinf framework to train a model capable of online code completion tasks.

Overview
--------

The online reinforcement learning for code completion agent system works through the following process:

1. **Real-time Interaction**: The system receives code completion requests from editors like Continue
2. **Model Inference**: Uses trained models to generate code completion suggestions
3. **User Feedback**: Collects user acceptance/rejection feedback on generated code
4. **Online Learning**: Updates model parameters in real-time based on user feedback

This real-time learning mechanism allows the model to quickly adapt to user programming habits and preferences.

Running the Script
------------------

**Environment Setup**

First, ensure you have installed the RLinf framework and its dependencies:

.. code-block:: bash

   # Install additional dependencies
   pip install httpx asyncio fuzzywuzzy

**Configure Continue Integration**

1. **Install Continue Extension**
   
   Since the current Continue does not support uploading user preference feedback on code completions, we have modified the Continue source code to support uploading user preference feedback on code completions.
   Users can get the compiled modified Continue plugin from `here <https://github.com/RLinf/continue/releases>`_ or build it themselves.

   After downloading the compiled Continue plugin, install it in VS Code.

   Method 1: code --install-extension /path/to/continue-1.3.9.vsix"

   Method 2: In VSCode, press Cmd+Shift+P, type 'Extensions: Install from VSIX', and select the above file

2. **Configure Continue Settings**

   The Continue configuration file path is:

   .. code-block:: bash

      ~/.continue/config.yaml

   Add the following settings to your Continue configuration file:

   .. code-block:: yaml

      # Please replace http://xxx:xx/ with the actual RLinf online code completion service address

      models:
      # Add a model for code completion
      - name: my-autocomplete
         provider: openai
         model: Qwen2.5-Coder-1.5B
         apiBase: http://xxx:8081/v1
         apiKey: xxx
         roles:
            - autocomplete

      # Add sending user feedback on whether to accept code completions
      tabAutocompleteOptions:
      enableCompletionTracking: true
      completionTrackingUrl: http://xxx:8082/api/training/submit
      completionTrackingHeaders:
         Authorization: "Bearer test-token"
         X-Project-ID: "test-project"
      maxPromptTokens: 1024
      debounceDelay: 350
      multilineCompletions: "auto"

   After modifying and saving, open the Continue extension from the left panel, click the "Settings" gear button in the top right corner, and ensure "Autocomplete Model" is set to my-autocomplete in the "Models" page.

**Start Training Service**

1. **Prepare Model and Configuration**
   
   Ensure you have pre-trained model weights and modify the configuration file to match model paths, ports to use, etc.

   .. code-block:: yaml

      rollout:
        model_dir: /path/to/your/model/DeepSeek-R1-Distill-Qwen-1.5B/
      
      actor:
        tokenizer:
          tokenizer_model: /path/to/your/model/DeepSeek-R1-Distill-Qwen-1.5B/

2. **Start RLinf Training Service**
   
   .. code-block:: bash

      # Navigate to project directory
      cd /path/to/rlinf_online_rl
      
      # Start training service
      bash examples/coding_online_rl/run_main_math_pipeline_grpo_megatron.sh qwen2.5-1.5b-ppo-megatron

   This will start the following services:
   - **Inference Service**: Provides code completion API on port 8081
   - **Training Service**: Receives user feedback data on port 8082

**Integration with Continue**

1. **Start Continue**
   
   Launch the Continue extension in VS Code, ensuring it connects to the correct API endpoints.

2. **Begin Programming**
   
   Start writing code in Continue. The system will:
   - Automatically send code completion requests to the inference service
   - Receive model-generated code suggestions
   - Collect your acceptance/rejection feedback on suggestions

3. **Real-time Learning**
   
   The system processes your feedback in real-time:
   - Accepted suggestions are marked as positive feedback
   - Rejected suggestions are marked as negative feedback
   - Model parameters are updated online based on feedback

**Monitor Training Process**

You can monitor the training process through the following methods:

1. **View Log Output**
   
   .. code-block:: bash

      # View training logs
      tail -f results/ppo-1.5b/train.log

2. **Use TensorBoard**
   
   .. code-block:: bash

      # Start TensorBoard
      tensorboard --logdir results/grpo-1.5b

3. **Check Model Checkpoints**
   
   Model checkpoints are periodically saved to the `results/grpo-1.5b/checkpoints/` directory during training.

**Test Client**

You can use the provided test client to verify system functionality:

.. code-block:: bash

   # Run test client
   python examples/coding_online_rl/simple_test_client.py

The test client simulates Continue behavior by sending code completion requests and submitting feedback data.

**Troubleshooting**

Common issues and solutions:

1. **Port Conflicts**
   
   If ports 8081 or 8082 are occupied, modify the port settings in the configuration file.

2. **Model Loading Failure**
   
   Check that the model path is correct and ensure model files exist and are accessible.

3. **Continue Connection Failure**
   
   Ensure the API endpoint addresses in Continue configuration are correct and check network connectivity. You can also use simple_test_client to test if feedback data can be received normally.

Through these steps, you can successfully run the online reinforcement learning for code completion agent system and achieve seamless integration with the Continue editor.
